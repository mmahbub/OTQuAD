{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95d768e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers.data.processors.squad import SquadV2Processor, SquadResult\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import spacy\n",
    "import json\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01b7b818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# random.seed(42)\n",
    "# random.randint(0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a40e216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_data = Path(\"/net/kdinxidk03/opt/NFS/75y/data/\")\n",
    "# processor = SquadV2Processor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c313abb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_filename_bioasq = \"bioasq/bioasq-squad/bioasq_squad_train_8B.json\"\n",
    "# data_filename_squad2 = \"squad/train-v1.1.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b66ce16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_out = Path(\"/net/kdinxidk03/opt/NFS/75y/data/OTMRC_PAPER/\")\n",
    "out_ft = \"/net/kdinxidk03/opt/NFS/75y/data/qa/features_cpg_biolinkbert/\"\n",
    "out_pair = \"/net/kdinxidk03/opt/NFS/75y/data/qa/qid_list_dir_cpg_biolinkbert/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69897066",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(out_ft):\n",
    "  os.makedirs(out_ft)\n",
    "  \n",
    "if not os.path.exists(out_pair):\n",
    "  os.makedirs(out_pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133fb4fc",
   "metadata": {},
   "source": [
    "    1. cached_train_biolinkbert_384_train_otquad_unsupervised_v1\n",
    "    2. cached_train_biolinkbert_384_train_otquad_unsupervised_v2_fold1\n",
    "    3. cached_train_biolinkbert_384_train_otquad_semisupervised_fold1\n",
    "    4. cached_train_biolinkbert_384_train_otquad_supervised_fold1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62493f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate = False\n",
    "model_name_or_path = \"biolinkbert\" #\"biobert-v1.1\"\n",
    "max_seq_length = 384\n",
    "\n",
    "def feature_to_folder(dataset_name, prefix): \n",
    "  cached_features_file = os.path.join(\n",
    "          path_out,\n",
    "#           \"cached_train_bioelectra_384_train_bioasq_9B_seed42_train\"\n",
    "          \"cached_{}_{}_{}_{}\".format(\n",
    "              \"dev\" if evaluate else \"train\",\n",
    "              list(filter(None, model_name_or_path.split(\"/\"))).pop(),\n",
    "              str(max_seq_length),\n",
    "              str(dataset_name),\n",
    "          )\n",
    "  )\n",
    "  print(cached_features_file)\n",
    "\n",
    "  features_and_dataset = torch.load(cached_features_file)\n",
    "  features, dataset, examples = (\n",
    "      features_and_dataset[\"features\"],\n",
    "      features_and_dataset[\"dataset\"],\n",
    "      features_and_dataset[\"examples\"],\n",
    "  )\n",
    "\n",
    "  print(len(features), len(dataset), len(examples))\n",
    "  \n",
    "  qid_list = []\n",
    "  for i in range(len(features)):\n",
    "    qid = features[i].__dict__['qas_id']\n",
    "    uid = features[i].__dict__['unique_id']\n",
    "    qid_list.append(f'{prefix}_{uid}')\n",
    "\n",
    "  file = open(out_pair+f'{prefix}_qid_list.txt', 'w')\n",
    "  for x in qid_list:\n",
    "    file.write(f'{x}\\n')\n",
    "  file.close()\n",
    "  \n",
    "  for i in range(len(qid_list)):\n",
    "\n",
    "    if i%5_000==0:\n",
    "      print(f'i: {i}')\n",
    "\n",
    "    feat = features[i]\n",
    "\n",
    "    input_ids = feat.input_ids\n",
    "    attention_masks = feat.attention_mask\n",
    "    token_type_ids = feat.token_type_ids\n",
    "    start_positions = feat.start_position\n",
    "    end_positions = feat.end_position\n",
    "    cls_index = feat.cls_index\n",
    "    p_mask = feat.p_mask\n",
    "    is_impossible = feat.is_impossible\n",
    "\n",
    "    uid = feat.__dict__['unique_id']\n",
    "    \n",
    "    cached_feat_file = out_ft + f'{prefix}_{uid}'\n",
    "    torch.save(\n",
    "      (\n",
    "        input_ids, attention_masks, token_type_ids, \n",
    "        start_positions, end_positions, cls_index,\n",
    "        p_mask, is_impossible\n",
    "      ),\n",
    "      cached_feat_file\n",
    "    )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e0c2adf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/net/kdinxidk03/opt/NFS/75y/data/OTMRC_PAPER/cached_train_biolinkbert_384_train_squad\n",
      "89789 89789 87599\n",
      "i: 0\n",
      "i: 5000\n",
      "i: 10000\n",
      "i: 15000\n",
      "i: 20000\n",
      "i: 25000\n",
      "i: 30000\n",
      "i: 35000\n",
      "i: 40000\n",
      "i: 45000\n",
      "i: 50000\n",
      "i: 55000\n",
      "i: 60000\n",
      "i: 65000\n",
      "i: 70000\n",
      "i: 75000\n",
      "i: 80000\n",
      "i: 85000\n",
      "/net/kdinxidk03/opt/NFS/75y/data/OTMRC_PAPER/cached_train_biolinkbert_384_train_otquad_unsupervised_v1\n",
      "11659 11659 10987\n",
      "i: 0\n",
      "i: 5000\n",
      "i: 10000\n",
      "/net/kdinxidk03/opt/NFS/75y/data/OTMRC_PAPER/cached_train_biolinkbert_384_train_otquad_unsupervised_v2_fold1\n",
      "12876 12876 11999\n",
      "i: 0\n",
      "i: 5000\n",
      "i: 10000\n",
      "/net/kdinxidk03/opt/NFS/75y/data/OTMRC_PAPER/cached_train_biolinkbert_384_train_otquad_unsupervised_v2_fold2\n",
      "12801 12801 11926\n",
      "i: 0\n",
      "i: 5000\n",
      "i: 10000\n",
      "/net/kdinxidk03/opt/NFS/75y/data/OTMRC_PAPER/cached_train_biolinkbert_384_train_otquad_unsupervised_v2_fold3\n",
      "12691 12691 11843\n",
      "i: 0\n",
      "i: 5000\n",
      "i: 10000\n",
      "/net/kdinxidk03/opt/NFS/75y/data/OTMRC_PAPER/cached_train_biolinkbert_384_train_otquad_unsupervised_v2_fold4\n",
      "12733 12733 11856\n",
      "i: 0\n",
      "i: 5000\n",
      "i: 10000\n",
      "/net/kdinxidk03/opt/NFS/75y/data/OTMRC_PAPER/cached_train_biolinkbert_384_train_otquad_unsupervised_v2_fold5\n",
      "12402 12402 11699\n",
      "i: 0\n",
      "i: 5000\n",
      "i: 10000\n",
      "/net/kdinxidk03/opt/NFS/75y/data/OTMRC_PAPER/cached_train_biolinkbert_384_train_otquad_semisupervised_fold1\n",
      "12867 12867 11999\n",
      "i: 0\n",
      "i: 5000\n",
      "i: 10000\n",
      "/net/kdinxidk03/opt/NFS/75y/data/OTMRC_PAPER/cached_train_biolinkbert_384_train_otquad_semisupervised_fold2\n",
      "12793 12793 11926\n",
      "i: 0\n",
      "i: 5000\n",
      "i: 10000\n",
      "/net/kdinxidk03/opt/NFS/75y/data/OTMRC_PAPER/cached_train_biolinkbert_384_train_otquad_semisupervised_fold3\n",
      "12683 12683 11843\n",
      "i: 0\n",
      "i: 5000\n",
      "i: 10000\n",
      "/net/kdinxidk03/opt/NFS/75y/data/OTMRC_PAPER/cached_train_biolinkbert_384_train_otquad_semisupervised_fold4\n",
      "12726 12726 11856\n",
      "i: 0\n",
      "i: 5000\n",
      "i: 10000\n",
      "/net/kdinxidk03/opt/NFS/75y/data/OTMRC_PAPER/cached_train_biolinkbert_384_train_otquad_semisupervised_fold5\n",
      "12398 12398 11699\n",
      "i: 0\n",
      "i: 5000\n",
      "i: 10000\n",
      "/net/kdinxidk03/opt/NFS/75y/data/OTMRC_PAPER/cached_train_biolinkbert_384_train_otquad_supervised_fold1\n",
      "1208 1208 1012\n",
      "i: 0\n",
      "/net/kdinxidk03/opt/NFS/75y/data/OTMRC_PAPER/cached_train_biolinkbert_384_train_otquad_supervised_fold2\n",
      "1134 1134 939\n",
      "i: 0\n",
      "/net/kdinxidk03/opt/NFS/75y/data/OTMRC_PAPER/cached_train_biolinkbert_384_train_otquad_supervised_fold3\n",
      "1024 1024 856\n",
      "i: 0\n",
      "/net/kdinxidk03/opt/NFS/75y/data/OTMRC_PAPER/cached_train_biolinkbert_384_train_otquad_supervised_fold4\n",
      "1067 1067 869\n",
      "i: 0\n",
      "/net/kdinxidk03/opt/NFS/75y/data/OTMRC_PAPER/cached_train_biolinkbert_384_train_otquad_supervised_fold5\n",
      "739 739 712\n",
      "i: 0\n"
     ]
    }
   ],
   "source": [
    "feature_to_folder('train_squad', 'squad')\n",
    "\n",
    "feature_to_folder('train_otquad_unsupervised_v1', 'unsupervised_v1')\n",
    "\n",
    "feature_to_folder('train_otquad_unsupervised_v2_fold1', 'unsupervised_v2_fold1')\n",
    "feature_to_folder('train_otquad_unsupervised_v2_fold2', 'unsupervised_v2_fold2')\n",
    "feature_to_folder('train_otquad_unsupervised_v2_fold3', 'unsupervised_v2_fold3')\n",
    "feature_to_folder('train_otquad_unsupervised_v2_fold4', 'unsupervised_v2_fold4')\n",
    "feature_to_folder('train_otquad_unsupervised_v2_fold5', 'unsupervised_v2_fold5')\n",
    "\n",
    "feature_to_folder('train_otquad_semisupervised_fold1', 'semisupervised_fold1')\n",
    "feature_to_folder('train_otquad_semisupervised_fold2', 'semisupervised_fold2')\n",
    "feature_to_folder('train_otquad_semisupervised_fold3', 'semisupervised_fold3')\n",
    "feature_to_folder('train_otquad_semisupervised_fold4', 'semisupervised_fold4')\n",
    "feature_to_folder('train_otquad_semisupervised_fold5', 'semisupervised_fold5')\n",
    "\n",
    "feature_to_folder('train_otquad_supervised_fold1', 'supervised_fold1')\n",
    "feature_to_folder('train_otquad_supervised_fold2', 'supervised_fold2')\n",
    "feature_to_folder('train_otquad_supervised_fold3', 'supervised_fold3')\n",
    "feature_to_folder('train_otquad_supervised_fold4', 'supervised_fold4')\n",
    "feature_to_folder('train_otquad_supervised_fold5', 'supervised_fold5')\n",
    "\n",
    "\n",
    "# 1. cached_train_biolinkbert_384_train_otquad_unsupervised_v1\n",
    "# 2. cached_train_biolinkbert_384_train_otquad_unsupervised_v2_fold1\n",
    "# 3. cached_train_biolinkbert_384_train_otquad_semisupervised_fold1\n",
    "# 4. cached_train_biolinkbert_384_train_otquad_supervised_fold1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eebc846",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_features_file = os.path.join(\n",
    "        path_out,\n",
    "#           \"cached_train_bioelectra_384_train_bioasq_9B_seed42_train\"\n",
    "        \"cached_{}_{}_{}_{}\".format(\n",
    "            \"dev\" if evaluate else \"train\",\n",
    "            list(filter(None, model_name_or_path.split(\"/\"))).pop(),\n",
    "            str(max_seq_length),\n",
    "            'train_bioasq_7B',\n",
    "        )\n",
    ")\n",
    "print(cached_features_file)\n",
    "\n",
    "features_and_dataset = torch.load(cached_features_file)\n",
    "features, dataset, examples = (\n",
    "    features_and_dataset[\"features\"],\n",
    "    features_and_dataset[\"dataset\"],\n",
    "    features_and_dataset[\"examples\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd82b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examples[random.randint(0,4000)].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d93071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cached_features_file = os.path.join(\n",
    "#         path_out,\n",
    "#         \"cached_{}_{}_{}_{}\".format(\n",
    "#             \"dev\" if evaluate else \"train\",\n",
    "#             list(filter(None, model_name_or_path.split(\"/\"))).pop(),\n",
    "#             str(max_seq_length),\n",
    "#             str('train_squad'),\n",
    "#         )\n",
    "# )\n",
    "\n",
    "# features_and_dataset = torch.load(cached_features_file)\n",
    "# features, dataset, examples = (\n",
    "#     features_and_dataset[\"features\"],\n",
    "#     features_and_dataset[\"dataset\"],\n",
    "#     features_and_dataset[\"examples\"],\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ea5c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(features), len(dataset), len(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb6c838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prep_data(examples):\n",
    "    \n",
    "#     question_list = []\n",
    "#     context_list = []\n",
    "#     answer_list = []\n",
    "#     qas_list = []\n",
    "#     is_imp_list = []\n",
    "\n",
    "#     for x in examples:\n",
    "#         qas_id = x.qas_id\n",
    "#         question_text = x.question_text\n",
    "#         context_text = x.context_text\n",
    "#         answers = x.answers\n",
    "#         is_imp = x.is_impossible\n",
    "        \n",
    "#         question_list.append(question_text)\n",
    "#         context_list.append(context_text)\n",
    "#         answer_list.append(answers)\n",
    "#         qas_list.append(qas_id)\n",
    "#         is_imp_list.append(is_imp)\n",
    "        \n",
    "#     df = pd.DataFrame()\n",
    "#     df['qas_id'] = qas_list\n",
    "#     df['question'] = question_list\n",
    "#     df['context'] = context_list\n",
    "#     df['answer'] = answer_list\n",
    "#     df['is_impossible'] = is_imp_list\n",
    "    \n",
    "#     return df\n",
    "\n",
    "\n",
    "# def get_df(data_filename):\n",
    "#     examples = processor.get_dev_examples(path_data, filename=data_filename)\n",
    "#     print(len(examples))\n",
    "#     df = prep_data(examples)\n",
    "#     return df\n",
    "\n",
    "\n",
    "# df_bioasq = get_df(data_filename_bioasq)\n",
    "# df_squad2 = get_df(data_filename_squad2)\n",
    "\n",
    "\n",
    "# # df_bioasq\n",
    "\n",
    "# train_bioasq, valid_bioasq = train_test_split(df_bioasq, test_size=0.2, random_state=42)\n",
    "# train_squad2, valid_squad2 = train_test_split(df_squad2, test_size=0.2, random_state=42)\n",
    "\n",
    "# train_bioasq.reset_index(inplace=True, drop=True)\n",
    "# valid_bioasq.reset_index(inplace=True, drop=True)\n",
    "# train_squad2.reset_index(inplace=True, drop=True)\n",
    "# valid_squad2.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# assert(len(train_bioasq)+len(valid_bioasq) == len(df_bioasq))\n",
    "# assert(len(train_squad2)+len(valid_squad2) == len(df_squad2))\n",
    "\n",
    "\n",
    "\n",
    "# def entry_to_json(squad_entries,title=None,version=None):\n",
    "#     squad_json={\n",
    "#               \"data\": [\n",
    "#                 {\n",
    "#                   \"paragraphs\":squad_entries,\n",
    "#                    \"title\":title\n",
    "#                 }],\n",
    "#                \"version\":version\n",
    "#            }\n",
    "#     return squad_json\n",
    "\n",
    "\n",
    "# def build_json(df, path_data, outfile_name, SQUAD2=True, BIOASQ=False):\n",
    "#     squad_entries = []\n",
    "#     for i in range(len(df)):\n",
    "#         id_num = df['qas_id'].values.tolist()[i]\n",
    "#         question = df['question'].values.tolist()[i]\n",
    "#         answer = df['answer'].values.tolist()[i]\n",
    "#         context = df['context'].values.tolist()[i]\n",
    "#         is_imp = df['is_impossible'].values.tolist()[i]\n",
    "\n",
    "#         new_entry={\n",
    "#                \"qas\": [\n",
    "#                  {\n",
    "#                   \"id\": id_num,\n",
    "#                   \"question\": question,\n",
    "#                   \"answers\": answer,\n",
    "#                   \"is_impossible\":is_imp\n",
    "#                  }\n",
    "#                  ],\n",
    "#                \"context\": context\n",
    "#                }\n",
    "\n",
    "#         squad_entries.append(new_entry)\n",
    "\n",
    "#     squad_json = entry_to_json(squad_entries)\n",
    "\n",
    "#     if SQUAD2:\n",
    "#         path = path_data/\"squad/\"\n",
    "#     elif BIOASQ:\n",
    "#         path = path_data/\"bioasq/bioasq-squad/\" \n",
    "#     else:\n",
    "#         path = path_data/\"otquad/\"\n",
    "\n",
    "#     with open(path/f\"{outfile_name}.json\", \"w\") as writer:\n",
    "#         writer.write(json.dumps(squad_json, indent=4) + \"\\n\") \n",
    "\n",
    "\n",
    "# build_json(train_squad2, path_data, \"train_squad1\", SQUAD2=True, BIOASQ=False)\n",
    "# build_json(valid_squad2, path_data, \"valid_squad1\", SQUAD2=True, BIOASQ=False)\n",
    "\n",
    "# build_json(train_bioasq, path_data, \"train_bioasq\", SQUAD2=False, BIOASQ=True)\n",
    "# build_json(valid_bioasq, path_data, \"valid_bioasq\", SQUAD2=False, BIOASQ=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e6f997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636b9325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fe4a29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(dataset_squad2), len(features_squad2), len(examples_squad2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dcdde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_squad2[0].__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf89f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make qid lists\n",
    "\n",
    "squad2_qid_list = []\n",
    "for i in range(len(features_squad2)):\n",
    "  qid = features_squad2[i].__dict__['qas_id']\n",
    "  uid = features_squad2[i].__dict__['unique_id']\n",
    "  squad2_qid_list.append(f's_{uid}')\n",
    "\n",
    "bioasq_qid_list = []\n",
    "for i in range(len(features_bioasq)):\n",
    "  qid = features_squad2[i].__dict__['qas_id']\n",
    "  uid = features_squad2[i].__dict__['unique_id']\n",
    "  bioasq_qid_list.append(f'b_{uid}')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf805679",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "  squad2_qid_list[-1],\n",
    "  bioasq_qid_list[-1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d74b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save qid lists\n",
    "\n",
    "\n",
    "\n",
    "file = open(out_pair+'bioasq_qid_list.txt', 'w')\n",
    "for x in bioasq_qid_list:\n",
    "  file.write(f'{x}\\n')\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f73cef5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import random\n",
    "# from copy import deepcopy\n",
    "\n",
    "# sample_done = []\n",
    "# sample_left = deepcopy(squad2_qid_list)\n",
    "# list_of_samples = []\n",
    "# while len(sample_left) > len(bioasq_qid_list):\n",
    "#   print(len(sample_left))\n",
    "#   sample = random.sample(sample_left, len(bioasq_qid_list))\n",
    "#   sample_done = sample_done + sample\n",
    "#   sample_left = list(set(sample_left)-set(sample_done))\n",
    "#   assert len(sample)==len(bioasq_qid_list)\n",
    "#   list_of_samples.append(sample)\n",
    "\n",
    "# len(list_of_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0826bef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = open(out_pair+f'bioasq_qid_pair.txt', 'w')\n",
    "\n",
    "# for i in range(len(bioasq_qid_list)):\n",
    "#   if i%1_000 == 0:\n",
    "#     print(f'i: {i}')\n",
    "#   x = bioasq_qid_list[i]\n",
    "#   for j in range(i+1, len(bioasq_qid_list), 1):\n",
    "#     y = bioasq_qid_list[j]\n",
    "#     file.write(f'{x} {y} 1 bioasq bioasq\\n')\n",
    "\n",
    "# file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5875dc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for l in range(len(list_of_samples)):\n",
    "#   print(l)\n",
    "#   sample = list_of_samples[l]\n",
    "#   file = open(out_pair+f'squad_bioasq_qid_pair_sample_{str(l)}.txt', 'w')\n",
    "  \n",
    "#   k = 0\n",
    "#   for x in sample:\n",
    "    \n",
    "#     if k%1_000 == 0:\n",
    "#       print(f'k: {k}')\n",
    "#     k+=1\n",
    "      \n",
    "#     for y in bioasq_qid_list:\n",
    "#       file.write(f'{x} {y} 0 squad bioasq\\n')\n",
    "\n",
    "#   file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93a8feb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# qas_0, qas_1, is_same_domain=1, 'squad2', 'squad2'\n",
    "\n",
    "# input_ids,\n",
    "# attention_masks,\n",
    "# token_type_ids,\n",
    "# start_positions,\n",
    "# end_positions,\n",
    "# cls_index,\n",
    "# p_mask,\n",
    "# is_impossible,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d2490f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# torch.save({\"features\": features, \"dataset\": dataset, \"examples\": examples}, cached_features_file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(features_bioasq)):\n",
    "  \n",
    "  if i%5_000==0:\n",
    "    print(f'i: {i}')\n",
    "\n",
    "  features = features_bioasq[i]\n",
    "  \n",
    "  input_ids = features.input_ids\n",
    "  attention_masks = features.attention_mask\n",
    "  token_type_ids = features.token_type_ids\n",
    "  start_positions = features.start_position\n",
    "  end_positions = features.end_position\n",
    "  cls_index = features.cls_index\n",
    "  p_mask = features.p_mask\n",
    "  is_impossible = features.is_impossible\n",
    "  \n",
    "  dataset = dataset_bioasq[i]\n",
    "  uid = features.__dict__['unique_id']\n",
    "\n",
    "  cached_features_file = out_ft + f'b_{uid}'\n",
    "  torch.save(\n",
    "    (\n",
    "      input_ids, attention_masks, token_type_ids, \n",
    "      start_positions, end_positions, cls_index,\n",
    "      p_mask, is_impossible\n",
    "    ),\n",
    "    cached_features_file\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcddcdd",
   "metadata": {},
   "source": [
    "dict_keys(['input_ids', 'attention_mask', 'token_type_ids', 'cls_index', 'p_mask', 'example_index', 'unique_id', 'paragraph_len', 'token_is_max_context', 'tokens', 'token_to_orig_map', 'start_position', 'end_position', 'is_impossible', 'qas_id', 'encoding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68738088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save({\"features\": features, \"dataset\": dataset, \"examples\": examples}, cached_features_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e013c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(8):\n",
    "  print(torch.tensor([torch.load(out_ft+'s_1000000000')[i]], dtype=torch.long).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63aa102",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
